---
sidebar_label: "模型选择指南"
---

# Kilo Code 模型选择指南

最后更新：2025年9月3日。

AI 模型领域发展迅速，因此本指南重点介绍目前在 Kilo Code 中表现优异的模型。我们会定期更新，以反映新模型的出现和性能变化。

## Kilo Code 表现最佳者

| 模型                 | 上下文窗口  | SWE-Bench 验证 | 人工评估 | LiveCodeBench | 输入价格\* | 输出价格\* | 最佳用途                 |
| -------------------- | ----------- | -------------- | -------- | ------------- | ---------- | ---------- | ------------------------ |
| **GPT-5**            | 400K tokens | 74.9%          | 96.3%    | 68.2%         | $1.25      | $10        | 最新功能，多模态编码     |
| **Claude Sonnet 4**  | 1M tokens   | 72.7%          | 94.8%    | 65.9%         | $3-6       | $15-22.50  | 企业级代码生成，复杂系统 |
| **Grok Code Fast 1** | 256K tokens | 70.8%          | 92.1%    | 63.4%         | $0.75      | $3.50      | 快速开发，性价比平衡     |
| **Qwen3 Coder**      | 256K tokens | 68.4%          | 91.7%    | 61.8%         | $0.20      | $0.80      | 纯编码任务，快速原型开发 |
| **Gemini 2.5 Pro**   | 1M+ tokens  | 67.2%          | 89.9%    | 59.3%         | TBD        | TBD        | 大型代码库，架构规划     |

\*每百万 tokens

## 高性价比选项

| 模型             | 上下文窗口  | SWE-Bench 验证 | 人工评估 | LiveCodeBench | 输入价格\* | 输出价格\* | 说明                     |
| ---------------- | ----------- | -------------- | -------- | ------------- | ---------- | ---------- | ------------------------ |
| **DeepSeek V3**  | 128K tokens | 64.1%          | 87.3%    | 56.7%         | $0.14      | $0.28      | 日常编码的超高性价比     |
| **DeepSeek R1**  | 128K tokens | 62.8%          | 85.9%    | 54.2%         | $0.55      | $2.19      | 预算价格下的高级推理能力 |
| **Qwen3 32B**    | 128K tokens | 60.3%          | 83.4%    | 52.1%         | Varies     | Varies     | 开源灵活性               |
| **Z AI GLM 4.5** | 128K tokens | 58.7%          | 81.2%    | 49.8%         | TBD        | TBD        | MIT 许可，混合推理系统   |

\*每百万 tokens

## 全面评估框架

### 延迟性能

响应时间显著影响开发流程和生产力：

- **超快 (< 2秒)**：Grok Code Fast 1，Qwen3 Coder
- **快速 (2-4秒)**：DeepSeek V3，GPT-5
- **中等 (4-8秒)**：Claude Sonnet 4，DeepSeek R1
- **较慢 (8-15秒)**：Gemini 2.5 Pro，Z AI GLM 4.5

**对开发的影响**：超快模型支持实时编码辅助和即时反馈循环。延迟超过 8 秒的模型可能会打断心流状态，但在处理复杂架构决策时可能仍然可以接受。

### 吞吐量分析

Token 生成速率影响大型代码库的处理：

- **高吞吐量 (150+ tokens/s)**：GPT-5，Grok Code Fast 1
- **中吞吐量 (100-150 tokens/s)**：Claude Sonnet 4，Qwen3 Coder
- **标准吞吐量 (50-100 tokens/s)**：DeepSeek 模型，Gemini 2.5 Pro
- **可变吞吐量**：开源模型依赖基础设施

**扩展因素**：高吞吐量模型在生成大量文档、重构大型文件或批量处理多个组件时表现出色。

### 可靠性与可用性

企业级生产环境的考虑：

- **企业级 (99.9%+ 正常运行时间)**：Claude Sonnet 4，GPT-5，Gemini 2.5 Pro
- **生产就绪 (99%+ 正常运行时间)**：Qwen3 Coder，Grok Code Fast 1
- **可靠性发展中**：DeepSeek 模型，Z AI GLM 4.5
- **自托管**：Qwen3 32B（可靠性取决于您的基础设施）

**成功率**：企业级模型保持一致的输出质量并更优雅地处理边缘情况，而预算选项可能需要额外的验证步骤。

### 上下文窗口策略

针对不同项目规模的优化：

| 大小             | 字数估算        | 典型用例                 | 推荐模型                               | 策略                     |
| ---------------- | --------------- | ------------------------ | -------------------------------------- | ------------------------ |
| **32K tokens**   | ~24,000 words   | 单个组件、脚本           | DeepSeek V3, Qwen3 Coder               | 专注于单文件优化         |
| **128K tokens**  | ~96,000 words   | 标准应用程序、大多数项目 | 所有预算模型, Grok Code Fast 1         | 多文件上下文，中等复杂度 |
| **256K tokens**  | ~192,000 words  | 大型应用程序、多个服务   | Qwen3 Coder, Grok Code Fast 1          | 完整功能上下文，服务集成 |
| **400K+ tokens** | ~300,000+ words | 企业系统、全栈应用       | GPT-5, Claude Sonnet 4, Gemini 2.5 Pro | 架构概览，系统级重构     |

**性能下降**：无论宣传的限制如何，模型的有效性通常在超过 400-500K tokens 后显著下降。请相应规划上下文使用。

## 社区选择

AI 模型领域变化迅速，要保持更新，请查看 [**👉 Kilo Code 在 OpenRouter 上的社区最爱**](https://openrouter.ai/apps?url=https%3A%2F%2Fkilocode.ai%2F)
